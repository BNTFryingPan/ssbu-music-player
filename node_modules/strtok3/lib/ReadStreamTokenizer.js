"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
const AbstractTokenizer_1 = require("./AbstractTokenizer");
const type_1 = require("./type");
const then_read_stream_1 = require("then-read-stream");
const _debug = require("debug");
const debug = _debug('strtok3:ReadStreamTokenizer');
const maxBufferSize = 1 * 1000 * 1000;
class ReadStreamTokenizer extends AbstractTokenizer_1.AbstractTokenizer {
    constructor(stream, fileSize) {
        super();
        this.streamReader = new then_read_stream_1.StreamReader(stream);
        this.fileSize = fileSize;
    }
    /**
     * Read buffer from tokenizer
     * @param buffer - Target buffer to fill with data read from the tokenizer-stream
     * @param offset - Offset in the buffer to start writing at; if not provided, start at 0
     * @param length - The number of bytes to read
     * @param position - Offset where to begin reading within the file. If position is null, data will be read from the current file position.
     * @param maybeless - If set, will not throw an EOF error if not all of the requested data could be read
     * @returns Promise with number of bytes read
     */
    async readBuffer(buffer, offset = 0, length = buffer.length, position) {
        // const _offset = position ? position : this.position;
        // debug(`readBuffer ${_offset}...${_offset + length - 1}`);
        if (length === 0) {
            return 0;
        }
        if (position) {
            const skipBytes = position - this.position;
            if (skipBytes > 0) {
                await this.ignore(position - this.position);
                return this.readBuffer(buffer, offset, length);
            }
            else if (skipBytes < 0) {
                throw new Error('Cannot read from a negative offset in a stream');
            }
        }
        let bytesRead;
        try {
            bytesRead = await this.streamReader.read(buffer, offset, length);
            this.position += bytesRead;
        }
        catch (err) {
            if (err.message === then_read_stream_1.endOfStream) // Convert EndOfStream into EndOfFile
                throw new Error(type_1.endOfFile);
            else
                throw err;
        }
        if (bytesRead < length) {
            throw new Error(type_1.endOfFile);
        }
        return bytesRead;
    }
    /**
     * Peek (read ahead) buffer from tokenizer
     * @param buffer - Target buffer to write the data read to
     * @param offset - The offset in the buffer to start writing at; if not provided, start at 0
     * @param length - The number of bytes to read
     * @param position - Specifying where to begin reading from in the file. If position is null, data will be read from the current file position.
     * @param maybeless - If set, will not throw an EOF error if the less then the requested length could be read
     * @returns Promise with number of bytes peeked
     */
    async peekBuffer(buffer, offset = 0, length = buffer.length, position, maybeless) {
        // const _offset = position ? position : this.position;
        // debug(`peek ${_offset}...${_offset + length - 1}`);
        let bytesRead;
        if (position) {
            const skipBytes = position - this.position;
            if (skipBytes > 0) {
                const skipBuffer = Buffer.alloc(length + skipBytes);
                bytesRead = await this.peekBuffer(skipBuffer, 0, skipBytes + length, undefined, maybeless);
                skipBuffer.copy(buffer, offset, skipBytes);
                return bytesRead - skipBytes;
            }
            else if (skipBytes < 0) {
                throw new Error('Cannot peek from a negative offset in a stream');
            }
        }
        try {
            bytesRead = await this.streamReader.peek(buffer, offset, length);
        }
        catch (err) {
            if (err.message === then_read_stream_1.endOfStream) // Convert EndOfStream into EndOfFile
                throw new Error(type_1.endOfFile);
            else
                throw err;
        }
        if (!maybeless && bytesRead < length) {
            throw new Error(type_1.endOfFile);
        }
        return bytesRead;
    }
    async ignore(length) {
        debug(`ignore ${this.position}...${this.position + length - 1}`);
        const bufSize = Math.min(maxBufferSize, length);
        const buf = Buffer.alloc(bufSize);
        let totBytesRead = 0;
        while (totBytesRead < length) {
            const remaining = length - totBytesRead;
            const bytesRead = await this.readBuffer(buf, 0, Math.min(bufSize, remaining));
            if (bytesRead < 0) {
                return bytesRead;
            }
            totBytesRead += bytesRead;
        }
        return totBytesRead;
    }
}
exports.ReadStreamTokenizer = ReadStreamTokenizer;
//# sourceMappingURL=ReadStreamTokenizer.js.map